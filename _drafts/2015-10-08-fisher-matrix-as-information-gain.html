---
layout: post
title: Fisher Matrix as Information Gain
date: '2015-10-08T07:52:00.000-07:00'
author: Robert Speare
tags:
- fisher information
- entropy
- cumulants. statistics
modified_time: '2015-10-19T10:48:58.644-07:00'
blogger_id: tag:blogger.com,1999:blog-3410852316732630293.post-6758838544243171009
blogger_orig_url: http://rspeare.blogspot.com/2015/10/fisher-matrix-as-information-gain.html
---

<div dir="ltr" style="text-align: left;" trbidi="on">From last post,&nbsp;<a href="http://rspeare.blogspot.com/2015/08/the-fisher-matrix-and-volume-collapse_31.html">http://rspeare.blogspot.com/2015/08/the-fisher-matrix-and-volume-collapse_31.html</a>, I was talking about "volume" collapse in parameter space due to some data, $\vec{x}$. I'd like to relate this to information gain, which can be defined pretty simply as:<br /><br />\begin{eqnarray}<br />H[p(\vec{\theta})] -&nbsp;H[p(\vec{\theta} \vert \vec{x})]&nbsp;&amp;=&amp; IG(\vec{\theta} \vert \vec{x})<br />\end{eqnarray}<br /><br />Now, using Bayes' rule we can change what we've written in the second term above:<br /><br />\begin{eqnarray}<br />H[p(\vec{\theta})] -&nbsp;H[p(\vec{\theta} \vert \vec{x})]&nbsp;&amp;=&amp; IG(\vec{\theta} \vert \vec{x})<br />\end{eqnarray}</div>