---
layout: post
title: Restricted (funky) Multinoulli samples
date: '2016-01-04T20:34:00.002-08:00'
author: Robert Speare
tags:
- Estimators
- random variables
- cumulants. statistics
modified_time: '2016-01-18T18:14:38.487-08:00'
blogger_id: tag:blogger.com,1999:blog-3410852316732630293.post-1714449131432767855
blogger_orig_url: http://rspeare.blogspot.com/2016/01/restricted-funky-multinoulli-samples.html
---

<div dir="ltr" style="text-align: left;" trbidi="on">I was asked an interesting question by a friend today, about density estimation. Let's say we're interested in some categorical variable $X$ that can take on integer values from $1$ to $C$. Let's say we have many instances of this random variable $X$ -- let's call them $x_t$ -- but for each instance $t$ we can only choose from a subset of our original possible values $1,\dots C$. How do we estimate the bin probabilities?<br /><br />Let's start simply and assume that at each time we have a complete choice over our original sample space, $x \in \Omega=\lbrace 1, \dots C \rbrace $. &nbsp;Then we can write down the PDF of a single sample or "trial" as a multinoulli:<br /><br />\begin{eqnarray}<br />P(X) &amp;=&amp; \prod_{c=1}^C \theta_c^{\mathbf{1}_{x=c}}<br />\end{eqnarray}<br /><br />Where $\mathbf{1}$ is the indicator function. If we have many realizations of this random variable $X$, we get a multinomial, and can write down our pdf in terms of the total number of times $X$ was equal to $c$ as $n_c$. If we have $N$ observations, that means:<br /><br />\begin{eqnarray}<br />P(\vec{n} \vert \vec{\theta}) &amp;=&amp; \frac{N!}{n_1! n_2! \cdots n_C!} \theta_1^{n_1}\theta_2^{n_2}\cdots \theta_C^{n_C}<br />\end{eqnarray}<br /><br />where we require<br /><br />\begin{eqnarray}<br />\sum_c n_c &amp;=&amp; N\\<br />\sum_c \theta_c &amp;=&amp; 1<br />\end{eqnarray}<br /><br />Note I've used the shorthand $\vec{n}=n_1,n_2,\dots n_C$ and $\vec{\theta}=\theta_1,\theta_2,\dots \theta_C$. What we've written above is the likelihood of a sequence of multinoulli observations, given some categorical probability distribution $\vec{\theta}$. One might ask, what's the maximum likelihood estimate of $\vec{\theta}$? &nbsp;If we maximize our likelihood subject to our normalization constraint on the PDF, we have<br /><br />\begin{eqnarray}<br />\mathrm{maximize} \ \ &amp;&amp; P(\vec{n} \vert \vec{\theta}) = \frac{N!}{\prod_c n_c!} \prod_c \theta_c^{n_c}\\<br />\mathrm{subject} \ \mathrm{to} \ &amp;&amp; \ \sum_c \theta_c = 1<br />\end{eqnarray}<br /><br />Taking the log and taking a derivative with respect to $\theta_c$ we get:<br /><br />\begin{eqnarray}<br />\frac{\partial}{\partial \theta_c} \left(\log P(\vec{n}\vert \vec{\theta}) +\lambda (1-\sum_c \theta_c)\right) &amp;=&amp; 0\\<br />&nbsp;\frac{\partial}{\partial \theta_c} \left( \log N! - \sum_c \log n_c! +\sum_c n_c \log \theta_c +\lambda (1-\sum_c \theta_c)\right) &amp;=&amp; 0 \\<br />&nbsp;\frac{n_c}{\theta_c} - \lambda &amp;=&amp; 0 \\<br />&nbsp;\theta_c &amp;=&amp; \frac{n_c}{\lambda}<br />\end{eqnarray}<br /><br />We can determine $\lambda$ by summing over $c$:<br /><br />\begin{eqnarray}<br />\sum_c \theta_c &amp;=&amp; \sum_c \frac{n_c}{\lambda} \\<br />1 &amp;=&amp; &nbsp;\frac{N}{\lambda} \\<br />\Rightarrow N &amp;=&amp; \lambda<br />\end{eqnarray}<br /><br />So finally, we have<br /><br />\begin{eqnarray}<br />\theta_c &amp;=&amp; \frac{n_c}{N}<br />\end{eqnarray}<br /><br />Ok, that's all well and good, in line with our intuition. We expect $X$ to fall into the categorical bin $c$ the number of times we observed it in there, normalized by our total observations!<br /><br />------------------------------------------------------------------------------------------------------------------------<br /><br /><br />Now, what if during these multinoulli trials, not all of the categorical variables -- or not all of our sample space $\Omega = \lbrace 1,...C \rbrace$ -- was available? Then we'd have to change our Likelihood estimation, because a pure count isn't quite the right thing to do. Let's nail down some notation. Our data is a sequence of categorical observations<br /><br />\begin{eqnarray}<br />\mathrm{Data} &amp;=&amp; \lbrace x_t \rbrace_{t=1}^T<br />\end{eqnarray}<br /><br />where, at each instance $t$, our categorical variable comes from a subset of our sample space:<br /><br />\begin{eqnarray}<br />x_t &amp;\in &amp; \Omega_t \subset \Omega<br />\end{eqnarray}<br /><br />This meas, if we were to write down the log likelihood, we'd have something like (assuming each $x_t$ is independent):<br /><br />\begin{eqnarray}<br />\log P(\lbrace x_t \rbrace_{t=1}^T \vert \vec{\theta}) &amp;=&amp; \sum_t \log P(x_t \in \Omega_t \vert \vec{\theta})<br />\end{eqnarray}<br /><br />The probability inside the sum can be written as a marginalization over the bins $c$ not included in the sample set $\Omega_t$<br /><br />\begin{eqnarray}<br />P(x_t \in \Omega_t \vert \vec{\theta}) &amp;=&amp; \sum_{x_t\ &nbsp;\not \in \ \Omega_t} P(x_t \vert \vec{\theta})<br />\end{eqnarray}<br /><br />and so our likelihood becomes:<br /><br />\begin{eqnarray}<br />\log P(\lbrace x_t \rbrace_{t=1}^T \vert \vec{\theta}) &amp;=&amp; \sum_t \log \left(\sum_{x_t\ &nbsp;\not \in \ \Omega_t} P(x_t \vert \vec{\theta})\right)<br />\end{eqnarray}<br /><br />You might look at the inner sum and say that all is lost, but if we group the outer sum in terms of common sample set, we can write:<br /><br /><br />\begin{eqnarray}<br />\log P(\lbrace x_t \rbrace_{t=1}^T \vert \vec{\theta}) &amp;=&amp; \sum_{S \subset \Omega} \left[ \sum_{S=\Omega_t} \log \left(\sum_{x_t\ &nbsp;\not \in \ \Omega_t} P(x_t \vert \vec{\theta})\right)\right]<br />\end{eqnarray}<br /><br />and now we see the term in brackets is just another multinomial with sample space $\Omega_t$. Converting our observed variables $x_t$ to counts, given sample space $S$, we get:<br /><br />\begin{eqnarray}<br />\log P(\lbrace x_t \rbrace_{t=1}^T \vert \vec{\theta}) &amp;=&amp; \sum_{S \subset \Omega} &nbsp;\log P(\vec{n}_S \vert \vec{\theta})<br />\end{eqnarray}<br /><br />You might be worried that we're summing over all possible subsets $S$, but we'll get to that implementation detail in a moment. The point is, we can now write our Likelihood as:<br /><br />\begin{eqnarray}<br />\log P(\lbrace x_t \rbrace_{t=1}^T \vert \vec{\theta}) &amp;=&amp; \sum_{S \subset \Omega} &nbsp;\left(\log(N_S!)-\sum_c \log(n_{c,S}!)+\sum_{c \in S} n_{c,S} \log \theta_c \right)<br />\end{eqnarray}<br /><br />To clarify, $N_S$ is the total number of observations we drew from the subset $S$, and $n_{c,S}$ is the count of categorical variable $c$ in all instances of the subset $S$. Adding our lagrange multipliers once again -- one for each subset -- we get:<br /><br />\begin{eqnarray}<br />\mathrm{minimize} \ \ &amp;&amp; \sum_{S \subset \Omega} &nbsp;\left(\log(N_S!)-\sum_c \log(n_{c,S}!)+\sum_{c \in S} n_{c,S} \log \theta_c \right) \\<br />\mathrm{subject} \ \mathrm{to} \ \ &amp;&amp; &nbsp;\sum_{c \in S} \theta_c =1 \ \forall S<br />\end{eqnarray}<br /><br />Taking the derivative once again with respect to $\theta_c$ we get a bunch of kronecker deltas -- or depending upon how you look at it, indicator functions -- in the sums:<br /><br />\begin{eqnarray}<br />\frac{\partial}{\partial \theta_c}\left( \sum_{S \subset \Omega} &nbsp;\left(\log(N_S!)-\sum_c \log(n_{c,S}!)+\sum_{c \in S} n_{c,S} \log \theta_c \right) + \sum_S \lambda_S (1-\sum_{c \in S} \theta_c )\right) &amp;=&amp; 0\\<br />\sum_{S \subset \Omega} \mathbf{1}_{c \in S} \frac{n_{c,S}}{\theta_c} - \sum_{S \subset \Omega} \lambda_S \mathbf{1}_{c \in S} &amp;=&amp; 0<br />\end{eqnarray}<br /><br />So we have:<br /><br />\begin{eqnarray}<br />\sum_{S \subset \Omega} \mathbf{1}_{c \in S} \frac{n_{c,S}}{\theta_c} &amp;=&amp; \sum_{S \subset \Omega} \lambda_S \mathbf{1}_{c \in S} &nbsp;\\<br />\theta_c &amp;=&amp; \frac{\sum_S n_{n_c,S} \mathbf{1}_{c \in S}}{\sum_S N_{S} \mathbf{1}_{c \in S}}<br />\end{eqnarray}<br /><br />or more simply,<br />\begin{eqnarray}<br />\theta_c &amp;=&amp; \frac{n_c}{\sum_S N_{S} \mathbf{1}_{c \in S}}<br />\end{eqnarray}<br /><br />So what does this final formula mean? It means our best estimate for the probability of our categorical bin $c$, given the data, is equal to the number of times we saw $X=c$, in general, divided by a new numerator, which, instead of $N$ is the number of times $X$ HAD A CHANCE to be equal to $c$. Pretty intuitive, but difficult to prove!<br /><br />Now back to that comment about summing over all subsets. In reality, for most data, you're only going to see a finite number of subsets of your categorical sample space (although things may become a pain if $C$ is really large). The best way to estimate these parameters is to do a masked sum. Let the data matrix be a binarized thing:<br /><br />\begin{eqnarray}<br />X_{tc} &amp;=&amp; 0,1 &nbsp;\\<br />\mathrm{where} \ &amp;&amp; t=1,\dots T, c=1,\dots C<br />\end{eqnarray}<br /><br />where $X_{tc}$ is unity if the $t^\mathrm{th}$ observation is equal to -- or falls into bin -- $c$. Now let our mask matrix be $M_{tc}$, which is zero if $c$ is not in $\Omega_t$ &nbsp;($c\ &nbsp;\not \in \ \Omega_t $ ) and one if it is. Then our estimates I wrote above are:<br /><br />\begin{eqnarray}<br />\theta_c &amp;=&amp;\frac{ \sum_t X_{tc} M_{tc}}{\sum_t &nbsp;M_{tc}}<br />\end{eqnarray}<br /><br />which can be done in numpy pretty darn fast.<br /><br />NOTE: I haven't put any priors on the bin probabilities, which might be a good idea, and if one bin is particularly rare, it is in general a good idea to Laplace smooth the bin counts!</div>