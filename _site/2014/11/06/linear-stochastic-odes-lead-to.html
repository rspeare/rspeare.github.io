<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="UTF-8">
  <title>rspeare.github.io</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  
</head>


  <body>
    <section class="page-header">
  <h1 <a href="/" class="project-name">rspeare.github.io </a> </h1> 
  <h2 class="project-tagline"></h2>
  <a href="/" class="btn">Blog</a>  

  <a class="btn" <a href="https://github.com/rspeare"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">rspeare</span></a>
 </a>


  <a class="btn" <a href="https://twitter.com/waiting4spark"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">waiting4spark</span></a>
 </a>

<a href="/about/" class="btn">About</a>  
</section>


    <section class="main-content">
      
      <style TYPE="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

<h2>Linear Stochastic ODE's lead to Gaussianity at Asymptotic times, even if Noise function has non-zero higher order Cumulants</h2>
<p class="meta">06 Nov 2014</p>

<div dir="ltr" style="text-align: left;" trbidi="on">So a few friends of mine 
are working on Stochastic ODE's and their connection to path integrals. After 
dorking out about this for a few moments, I'm able to make some ``baby'' 
statements about the problem. If you consider a sequence of random numbers: 

\begin{eqnarray} 
\left \lbrace \mathbf{X}_i \right \rbrace_{i=1}^n 
\end{eqnarray} 

which is determined by the following difference equation: 

\begin{eqnarray} 
d\mathbf{X}_i = \mathbf{X}_{i+1} - \mathbf{X}_i &amp;=&amp; a_i+\mathbf{W}_i 
\end{eqnarray} 

subject to the initial condition $\mathbf{X}_0=0$ 

You can express the solution as a sum of two sums -- one deterministic and one 
random. 

\begin{eqnarray} 
X_n &amp;=&amp; \sum_{i=0}^n a_i + \sum_{i=1}^n \mathbf{W_i} 
\end{eqnarray} 

Where I have boldfaced all random variables. For instance $a_i$ is a real 
sequence of numbers, perhaps they are the same for all $i$. $\mathbf{W}$ is a 
noise variable, or some random forcing function. We see that the solution 
after N steps will be 

\begin{eqnarray} 
\mathbf{X}_n &amp;=&amp; n a+ \sum_{i=1}^n \mathbf{W}_i 
\end{eqnarray} 

Now, if we see that $\mathbf{W}_i$ is drawn from some probability distribution 
at every single step $i$, we know that, at asymptotic times $N \to \infty$, 
subject to certain conditions on the probability density of $W_i$, our 
distribution on $\mathbf{X}$ will converge to a Gaussian. This is very cool, 
and not necessarily dependent on $\mathbf{W}$ being an identically 
independently distributed variable. We simply say  that if 
\begin{eqnarray} 
\mathbf{W_i} &amp; \sim &amp; N(0,\sigma^2) \ \ \forall i 
\end{eqnarray} 

then, 
\begin{eqnarray} 
\mathbf{X_N} &amp;\sim &amp; na(t)+ N(0, n \sigma^2) 
\end{eqnarray} 

Where $N(0,\sigma^2)$ stands for a normal distribution with zero mean and 
variance $\sigma^2$. Note that, this is simply a conclusion from the addition 
of cumulants under convolution -- which is what you do when add random 
variables. 

\begin{eqnarray} 
Z&amp;=&amp;X+Y \\ 
X &amp; \sim &amp; N(c_1, c_2)\\ 
Y &amp; \sim &amp; N(c_1^\prime, c_2^\prime )\\ 
Z &amp; \sim &amp; N(c_1+c_1^\prime, c_2+ c_2^\prime ) 
\end{eqnarray} 

So our cumulants add, and the central limit theorem hinges upon this, because 
since our characteristic function -- or the fourier transform of our 
probability distribution -- is bounded above by one (1), when we convolve tow 
distributions in real space we multiply in frequency space, making the 
characteristic function of our result variable $Z$ -- which is very much like 
an average, thinner and thinner and thinner... Meaning that you can truncate 
the characteristic function's cumulant generating function $\psi$ at order 
$k^2$, leading to a Gaussian. 

This means that any sum of random variables, even they are not identically and 
independently distributed -- although they must be independent in order to 
convolve -- and even if those variables have non-zero higher order cumulants, 
like skewness $c_3$ or kurtosis $c_4$, will give you a Gaussian in the $n \to 
\infty$ limit. This is an analog of the law of large numbers. 

So why do we care in this Stochastic ODE case? It means that under linear 
dynamics, at asymptotic times, we converge to a Gaussian distribution on 
$\mathbf{X}$, even our noise function itself has very strange properties, like 
higher order cumulants. This is very strange indeed, and comes from the fact 
that system is **linear**, i.e. we are **adding** random variables together. 

Under non-linear evolution, it can be shown using Perturbation theory that 
non-zero third and higher order moments are created, but showing this in the 
stochastic framework is a bit difficult... 

It is easy to show however, that an equation like: 

\begin{eqnarray} 
L_0 \delta &amp;=&amp; \delta^2 
\end{eqnarray} 

where $L_0$ is some linear differential operator, can be expanded in power 
series of small parameter $\lambda$ 
\begin{eqnarray} 
L_0 \delta &amp;=&amp; \lambda \delta^2\\ 
\delta &amp;=&amp; \sum_{i=1}^\infty \lambda^i \delta_i 
\end{eqnarray} 

So we have, to each order: 

\begin{eqnarray} 
\lambda^0 : L_0 \delta_0 &amp;=&amp; 0 
\end{eqnarray} 

which is our linear solution. Then we have to leading order: 
\begin{eqnarray} 
\lambda^1: L_0 \delta_1 &amp;=&amp; \delta_0^2 
\end{eqnarray} 

Now we find, that if we take the connected third moment, or the third 
cumulant, we get a nonzero value: 

\begin{eqnarray} 
\langle \delta^3 \rangle &amp;=&amp; \langle \delta_0 ^3 \rangle +\lambda 
\langle \delta_0^2 \delta_1 \rangle + \dots 
\end{eqnarray} 

If $\delta_0$ is Gaussian distributed, as we found that we would be for some 
driving function at asymptotic times -- or if we simply assume Gaussian 
initial conditions -- then we know that $\langle \delta_0^3 \rangle =0$. The 
leading order term however, will not be zero, because it goes like $ \sim 
\delta_0^4 $, which under Wick's theorem/Gaussian statistics can be built out 
of second cumulants. So see that non-linearity gives non-zero skewness and 
kurtosis, and other higher order things, at late times. 

The key to connecting this with Stochastic ODE's lies in the fact that we are 
not adding random variables anymore but multiplying them, and this is a very 
peculiar type of convolution, which in general does **not do a simple 
addition** of cumulants. I will have to look more into this. 

Note: The lognormal distribution is the convergent distribution for a product 
of random variables, since the log of the product is the sum of the logs. So 
perhaps it could be shown that some non-linear Stochastic ODE's go to a 
lognormal (which I believe is already a common concept on Wall street, for 
estimating the dynamics stock prices). 
<div> 
</div></div>




      <footer class="site-footer">
  <span class="site-footer-owner"><a href="http://localhost:4000">rspeare.github.io</a> is maintained by <a href="">rspeare</a>.</span>
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>

  <a href="https://www.linkedin.com/in/rob-speare-aaa6834a">
    <span class="icon  icon--linkedin">
      <svg viewBox="0 0 10000 10000" >
        <path fill="#828282" d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683
        C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z
        M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615
        c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915
        s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z"/>
      </svg>
    </span>

    <span class="username"></span>
  </a>

</footer>
 

    </section>

  </body>
</html>
