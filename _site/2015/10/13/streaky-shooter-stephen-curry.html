<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="UTF-8">
  <title>rspeare.github.io</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/cayman.css">
  
</head>


  <body>
    <section class="page-header">
  <h1 <a href="/" class="project-name">rspeare.github.io </a> </h1> 
  <h2 class="project-tagline"></h2>
  <a href="/" class="btn">Blog</a>  

  <a class="btn" <a href="https://github.com/rspeare"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">rspeare</span></a>
 </a>


  <a class="btn" <a href="https://twitter.com/waiting4spark"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">waiting4spark</span></a>
 </a>

<a href="/about/" class="btn">About</a>  
</section>


    <section class="main-content">
      
      <style TYPE="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

<h2>Streaky Shooter, Stephen Curry</h2>
<p class="meta">13 Oct 2015</p>

<div dir="ltr" style="text-align: left;" trbidi="on">So, recently I was given 
the following problem: let's say some basketball player has an a priori 
probability  $P(y_1=1)=0.35$ of making  a three point shot. This implies the 
probability of missing the three-pointer is $P(y=0)=0.65$. (Note that $y=1$ 
denotes ``make'' and $y=0$ ``miss''.) Pretty good odds, for an NBA player -- I 
think. 

But let's say that our basketball player is streaky, in the sense that 
$P(y_2=1 \vert y_1=1)=0.6$, or the probability of making the next shot, given 
that he made the previous, is sixty percent. (This implies $P(y_2=0 \vert 
y_1=1)=0.4$.) And conversely, the probability of making the next shot, given 
that he missed the previous is a bit lower than the prior, $P(y_2=1 \vert 
y_0=0)=0.3$, which implies $P(y_2=0 \vert y_0=0)=0.7$. This defines something 
called a markov process, in the sense that the $n^\mathrm{th}$ shot only 
depends on the one before it. 

\begin{eqnarray} 
P(y_n \vert y_{n-1},y_{n-2},\dots y_2,y_1) &amp;=&amp; P(y_n \vert y_{n-1}) 
\end{eqnarray} 

To repeat an old aphorism: ``the future to depends on the past only through 
the present''. We can represent this conditional probability density with a 
matrix, 

\begin{eqnarray} 
P(y_n \vert y_{n-1}) &amp;=&amp; \mathbf{W}= \left(\begin{array}{cc} 
.6 &amp; .3 \\ 
.4 &amp; .7 \\ 
\end{array}\right) 
\end{eqnarray} 

and the a priori probability density with a vector: 

\begin{eqnarray} 
P(y_1) &amp;=&amp; \left(\begin{array}{c} 
0.35 \\ 
0.65 
\end{array}\right) 
\end{eqnarray} 

If we want to write down the joint probability density on a few shots, we can 
use Bayes' chain rule: 

\begin{eqnarray} 
P(y_3, y_2,y_1) &amp;=&amp; P(y_3 \vert y_2, y_1) P(y_2 \vert y_1) P(y_1) 
\end{eqnarray} 

which by markov property simplifies to 

\begin{eqnarray} 
P(y_3, y_2,y_1) &amp;=&amp; P(y_3 \vert y_2) P(y_2 \vert y_1) P(y_1) 
\end{eqnarray} 

Marginalizing over $y_2$ we see that we have a matrix multiplication: 

\begin{eqnarray} 
\sum_{y_2} P(y_3, y_2,y_1) &amp;=&amp; \sum_{y_2}  P(y_3 \vert y_2) P(y_2 
\vert y_1) P(y_1)\\ 
P(y_3,y_1) &amp;=&amp; \sum_{y_2}  P(y_3 \vert y_2) P(y_2 \vert y_1) P(y_1) 
\end{eqnarray} 

and, dividing through by $P(y_1)$ is the same as conditioning on $y_1$, so we 
have a new conditional probability, which connects the third shot to the 
first: 

\begin{eqnarray} 
P(y_3 \vert y_1) &amp;=&amp; \sum_{y_2}  P(y_3 \vert y_2) P(y_2 \vert y_1) 
\end{eqnarray} 

This is often called the Chapman Kolgomorov equation, and is the basis for 
much analysis in physics of the rate of change of probability distributions 
through the master equation and Fokker-Planck equation. 

It's pretty easy to see that any conditional distribution can now be written 
as $n-1$ matrix contractions: 

\begin{eqnarray} 
P(y_n \vert y_1) &amp;=&amp; (\mathbf{W})^{n-1} 
\end{eqnarray} 

If we multiply by the vector $P(y_1)$, we get the distribution on $y_n$ alone, 
since 

\begin{eqnarray} 
P(y_2) &amp;=&amp; \sum_{y_1} P(y_2 \vert y_1)P(y_1)\\ 
&amp;=&amp; \mathbf{W}\cdot \vec{\mathbf{P}}_1 \\ 
P(y_n) &amp;=&amp; (\mathbf{W})^{n-1} \cdot \vec{\mathbf{P}}_1 
\end{eqnarray} 

But Markov matrices, since their columns add to unity and have strictly 
non-negative entries have some very useful properties (the Perron-Frobenius 
Theorem). Their spectra -- or eigenvalues -- all lie within the unit circle in 
the complex plane, and there is guaranteed to be some eigenvector 
$\mathbf{\pi}$ with an eigenvalue $\lambda=1$. This eigenvector is called the 
stationary distribution, and after $n \to \infty$ time steps, we expect our 
distribution to converge to $\mathbf{\pi}$. For the matrix given above, this 
vector is 

\begin{eqnarray} 
\mathbf{\pi} &amp;=&amp; \left(\begin{array}{c} 
0.428 \\ 
0.572 
\end{array}\right) 
\end{eqnarray} 

So after sufficient shots, our shooter will converge to a 42.8 percent success 
rate, as compared to 35 -- or whatever you specified. This discrepancy is 
important, as the expected number of buckets given $m$ shots does not go like 
a binomial distribution 

\begin{eqnarray} 
\langle \sum_i y_i \rangle &amp;=&amp; m p_0 \\ 
p_0=0.35 
\end{eqnarray} 

but something slightly different. More like a binomial process with changing 
parameter $p$. As $m$ gets large we expect 

\begin{eqnarray} 
\langle \sum_i y_i \rangle &amp;\approx &amp; m \pi_0 \\ 
\pi_0 &amp;=&amp; 0.428 = \frac{3}{7} 
\end{eqnarray} 
</div>




      <footer class="site-footer">
  <span class="site-footer-owner"><a href="http://localhost:4000">rspeare.github.io</a> is maintained by <a href="">rspeare</a>.</span>
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>

  <a href="https://www.linkedin.com/in/rob-speare-aaa6834a">
    <span class="icon  icon--linkedin">
      <svg viewBox="0 0 10000 10000" >
        <path fill="#828282" d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683
        C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z
        M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615
        c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915
        s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z"/>
      </svg>
    </span>

    <span class="username"></span>
  </a>

</footer>
 

    </section>

  </body>
</html>
